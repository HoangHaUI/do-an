{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 E:\\do-an\\images\\multibottle\\chuan\\z4229996124844_43500e5ce281f560b4ac860cc2716092.jpg: 640x480 3 bottles, 3 vases, 172.0ms\n",
      "Speed: 1.0ms preprocess, 172.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict5\u001b[0m\n",
      "1 label saved to runs\\detect\\predict5\\labels\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"Yolo/yolov8s.pt\")\n",
    "ret = model('E:/do-an/images/multibottle/chuan/z4229996124844_43500e5ce281f560b4ac860cc2716092.jpg', save=True,  save_txt=True, save_conf=True)\n",
    "print(\"FINSIH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ret[\u001b[39m'\u001b[39;49m\u001b[39mboxes\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "ret['boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "paths = glob(r\"E:\\do-an\\images\\multibottle\\**\\*.jpg\")\n",
    "print(len(paths))\n",
    "for path in paths:\n",
    "    model(path, save=True,  save_txt=True, save_conf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def get_coord(img_path :str, txt_path :str):\n",
    "    # Lay toa do doi tuong 39\n",
    "    img = cv2.imread(img_path)\n",
    "    dh, dw, _ = img.shape\n",
    "    fl = open(txt_path, 'r')\n",
    "    data = fl.readlines()   \n",
    "    fl.close()\n",
    "\n",
    "    for dt in data:\n",
    "\n",
    "        # Split string to float\n",
    "        _, x, y, w, h, acc = map(float, dt.split(' '))\n",
    "        if acc < 0.7:\n",
    "            return\n",
    "\n",
    "        # Taken from https://github.com/pjreddie/darknet/blob/810d7f797bdb2f021dbe65d2524c2ff6b8ab5c8b/src/image.c#L283-L291\n",
    "        # via https://stackoverflow.com/questions/44544471/how-to-get-the-coordinates-of-the-bounding-box-in-yolo-object-detection#comment102178409_44592380\n",
    "        l = int((x - w / 2) * dw)\n",
    "        r = int((x + w / 2) * dw)\n",
    "        t = int((y - h / 2) * dh)\n",
    "        b = int((y + h / 2) * dh)\n",
    "        \n",
    "        if l < 0:\n",
    "            l = 0\n",
    "        if r > dw - 1:\n",
    "            r = dw - 1\n",
    "        if t < 0:\n",
    "            t = 0\n",
    "        if b > dh - 1:\n",
    "            b = dh - 1\n",
    "        b_nap = (int)((b-t)/8) + t\n",
    "        t_nhan = (int)((b-t)/8) + t\n",
    "        print(os.path.basename(img_path))\n",
    "\n",
    "        cv2.imwrite('E:\\\\do-an\\\\images\\\\multibottle\\\\training\\\\nap\\\\' + os.path.basename(img_path), img[t:b_nap, l:r])\n",
    "        cv2.imwrite('E:\\\\do-an\\\\images\\\\multibottle\\\\training\\\\nhan\\\\' + os.path.basename(img_path), img[t_nhan:b, l:r])\n",
    "        return img[t:b, l:r]\n",
    "        # img.crop[]\n",
    "\n",
    "# img = get_coord('./images/multibottle/chuan/z4229996124844_43500e5ce281f560b4ac860cc2716092.jpg', r'E:\\do-an\\runs\\detect\\predict\\labels\\z4229996124844_43500e5ce281f560b4ac860cc2716092.txt')\n",
    "# cv2.imwrite( \"test.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np  \n",
    "from PIL import Image \n",
    "from glob import glob\n",
    "\n",
    "classes = ['nap', 'nhan', 'thieu_nap', 'thieu_nhan']\n",
    "# Crop image to train model classify\n",
    "paths = glob(r\"./runs/detect/predict/labels/*.txt\")\n",
    "img = []\n",
    "for path in paths:\n",
    "    base_name = os.path.basename(path).split('.')[0]\n",
    "    coord_nap = []\n",
    "    coord_nhan = []\n",
    "    for class_name in classes:\n",
    "        image_path = \"./images/multibottle/\"+class_name + \"/\"+base_name+\".jpg\"\n",
    "        if os.path.exists(image_path):\n",
    "            print(\"Img path : \" , image_path)\n",
    "            get_coord(image_path, path)\n",
    "    # get coord vi txt file\n",
    "    \n",
    "            \n",
    "    # img_nap = img.\n",
    "    # break\n",
    "\n",
    "# img.resize([200,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_crop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2051b4c56d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from src.training.load_model import load_model\n",
    "from src.training.load_image import get_dataset\n",
    "\n",
    "checkpoint_dir = \"runs/training/\"\n",
    "# Load model\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest\n",
    "# Create a new model instance\n",
    "model = load_model(4)\n",
    "\n",
    "# Load the previously saved weights\n",
    "model.load_weights(latest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.0 0.0\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "./images/multibottle/testing\\z4229996229742_5169139970ea706caa560df927b400fc.jpg\n",
      "This image most likely belongs to nap with a 47.54 percent confidence.\n",
      "255.0 0.0\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "./images/multibottle/testing\\z4229996237355_e86249b1e89dbadca6d65c1196011776.jpg\n",
      "This image most likely belongs to nap with a 47.54 percent confidence.\n",
      "255.0 0.0\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./images/multibottle/testing\\z4229996249916_dccc04e82340cd926ea84605ce7b5a8c.jpg\n",
      "This image most likely belongs to nap with a 47.54 percent confidence.\n",
      "255.0 26.0\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "./images/multibottle/testing\\z4230020025736_ad5c296bcaf343c85c6a0777e0b59706.jpg\n",
      "This image most likely belongs to thieu_nap with a 47.33 percent confidence.\n",
      "255.0 0.0\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "./images/multibottle/testing\\z4230030853056_071f2760ec1755674a58bb6425fa4d7a.jpg\n",
      "This image most likely belongs to nhan with a 47.54 percent confidence.\n",
      "255.0 0.0\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "./images/multibottle/testing\\z4230031125486_b60dd61bd22b92fd61cdb876471235cc.jpg\n",
      "This image most likely belongs to nhan with a 47.54 percent confidence.\n",
      "255.0 0.0\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./images/multibottle/testing\\z4230031843920_98094ca1a2e4aa95a2cd28322de1c143.jpg\n",
      "This image most likely belongs to thieu_nhan with a 47.53 percent confidence.\n",
      "255.0 0.0\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./images/multibottle/testing\\z4230031853623_c80446e9f2f542b6d83376bce018591c.jpg\n",
      "This image most likely belongs to thieu_nhan with a 47.53 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from glob import glob\n",
    "testing_image = glob(\"./images/multibottle/testing/*.jpg\")\n",
    "for path in testing_image:\n",
    "    # Evaluate\n",
    "    img = tf.keras.utils.load_img(\n",
    "        path, target_size=(244, 244)\n",
    "    )\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "    print(np.max(img_array[0]), np.min(img_array[0]))\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    # _,_,class_names = get_dataset()\n",
    "    \n",
    "    print(path)\n",
    "\n",
    "    class_names = ['nap', 'nhan', 'thieu_nap', 'thieu_nhan']\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([118, 137, 144, ..., 111, 206, 252], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "path = './images/multibottle/testing/z4230031125486_b60dd61bd22b92fd61cdb876471235cc.jpg'\n",
    "img = tf.keras.utils.load_img(\n",
    "        path, target_size=(244, 244)\n",
    "    )\n",
    "np.asarray(img).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1e860536730>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from src.training.load_model import load_model\n",
    "from src.common import get_crop_image\n",
    "import sys\n",
    "from PyQt6 import QtCore, QtGui, QtWidgets\n",
    "from PyQt6 import uic\n",
    "from PyQt6.QtWidgets import (QMainWindow, QTextEdit,\n",
    "        QFileDialog, QApplication)\n",
    "from PyQt6.QtGui import QPixmap\n",
    "\n",
    "\n",
    "from PyQt6.QtCore import *\n",
    "from PyQt6.QtGui import *\n",
    "from PyQt6.QtWidgets import QWidget\n",
    "\n",
    "import cv2 as cv\n",
    "from ultralytics import YOLO\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# Load Yolo model\n",
    "yolo_model = YOLO(\"Yolo/yolov8s.pt\")\n",
    "\n",
    "checkpoint_dir = \"runs/training/\"\n",
    "# Load model \n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest\n",
    "# Create a new model instance\n",
    "model = load_model(4)\n",
    "\n",
    "# Load the previously saved weights\n",
    "model.load_weights(latest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (14300173.py, line 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[23], line 60\u001b[1;36m\u001b[0m\n\u001b[1;33m    predict\"E:\\do-an\\images\\multibottle\\training\\thieu_nap\\z4230019598257_0731a43b5e2678e05de405485f733c98.jpg\")\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 E:\\do-an\\images\\multibottle\\img_org\\thieu_nap\\z4230019226618_434ae9989122909c759c2d19139f939f.jpg: 640x480 3 bottles, 3 vases, 196.7ms\n",
      "Speed: 2.0ms preprocess, 196.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict42\u001b[0m\n",
      "5 labels saved to runs\\detect\\predict42\\labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 244, 244, 3)\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "        \n",
    "\n",
    "ret , img = predict(\"E:/do-an/images/multibottle/img_org/thieu_nap/z4230019226618_434ae9989122909c759c2d19139f939f.jpg\")\n",
    "cv.imwrite(\"test.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions_nap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions_nap\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions_nap' is not defined"
     ]
    }
   ],
   "source": [
    "predictions_nap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf0d741d5f36cb72faa016d1262c773a39cfb7e80732ae65e560a70de48671cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
